## 基础知识

### 公钥和私钥

1.每个用户都有一对私钥和公钥。

- 私钥用来进行解密和签名，是给自己用的。
- 公钥由本人公开，用于加密和验证签名，是给别人用的。

问：如何安全的传输数据，不让第三方窃取？

 **当该用户接受文件时，别人用他的公钥加密，他用私钥解密，可以保证该信息只能由他看到。即安全传输。**

问：如何确保接收到的文件是对方发的？

 **当该用户发送文件时，用私钥签名，别人用他给的公钥解密，可以保证该信息是由他发送的。即数字签名。**

### 加密缘由

​	假设Bob要给Alice发一封邮件，在邮件传送的过程中，黑客可能会窃取到邮件的内容，所以需要防窃听。黑客还可能会篡改邮件的内容，Alice必须有能力识别出邮件有没有被篡改。最后，黑客可能假冒Bob给Alice发邮件，Alice必须有能力识别出伪造的邮件。

所以，应对潜在的安全威胁，需要做到三防：

- 防窃听 （加密）
- 防篡改（Hash映射算法，又称摘要算法。有MD5、SHA256等）
- 防伪造（签名算法）

### 对称加密

常用的：

​	**DES**（DES算法由于密钥过短，可以在短时间内被暴力破解，所以现在已经不安全了。）

​	**AES**（是目前应用最广泛的加密算法）

### 非对称加密（公钥加密）

**非对称加密相比对称加密的显著优点在于：**

​	对称加密需要协商密钥，而非对称加密可以安全地公开各自的公钥，在N个人之间通信的时候。

​	使用非对称加密只需要N个密钥对，每个人只管理自己的密钥对。而使用对称加密需要则需要`N*(N-1)/2`个密钥，因此每个人需要管理`N-1`个密钥，密钥管理难度大，而且非常容易泄漏。

**缺点：**

​	因为非对称加密的缺点就是运算速度非常慢，比对称加密要慢很多。

**所以，在实际应用的时候，非对称加密总是和对称加密一起使用。**如：还是使用对称加密算法加密/解密文件，但采用非对称加密进行传输随即口令（生成密钥的口令），使得双方密钥一致。

​	这也是浏览器中常用的HTTPS协议的做法，即浏览器和服务器先通过RSA交换AES口令，接下来双方通信实际上采用的是速度较快的AES对称加密，而不是缓慢的RSA非对称加密。

常用的：

​	RSA算法

​	DSA算法

​	ECC算法

​	DH算法

### 签名算法

与非对称加密相反：使用私钥加密，公钥解密。因为私钥只有一个，可以唯一确认是谁发的，不能伪造信息发送。

在实际应用的时候，签名实际上并不是针对原始消息，而是针对原始消息的哈希进行签名，即：

```
signature = encrypt(privateKey, sha256(message))
```

对签名进行验证实际上就是用公钥解密：

```
hash = decrypt(publicKey, signature)
```

然后把解密后的哈希与原始消息的哈希进行对比。

常用数字签名算法有(先hash算法再非对称算法)：

- MD5withRSA
- SHA1withRSA
- SHA256withRSA

### 数字证书

摘要算法用来确保数据没有被篡改，非对称加密算法可以对数据进行加解密，签名算法可以确保数据完整性和抗否认性，把这些算法集合到一起，并搞一套完善的标准，这就是数字证书。

因此，数字证书就是集合了多种密码学算法，用于实现数据加解密、身份认证、签名等多种功能的一种安全标准。



## 安全方向

### 多方安全计算:

#### **1、秘密共享**

​	秘密共享的思想是将秘密以适当的方式拆分，拆分后的每一个份额由不同的参与者管理，单个参与者无法恢复秘密信息，只有若干个参与者一同协作才能恢复秘密消息。更重要的是，当其中任何相应范围内参与者出问题时，秘密仍可以完整恢复。

https://www.zhihu.com/search?type=content&q=%E7%A7%98%E5%AF%86%E5%85%B1%E4%BA%AB

#### **2、不经意传输**

#### **3、零知识证明**

​	零知识证明指的是证明者能够在不向验证者提供任何有用信息的情况下，使验证者相信某个论断是正确的。允许证明者 prover、验证者 verifier 证明某项提议的真实，却不必泄露除了「提议是真实的」之外的任何信息。

#### **4、混淆电路**



### 同态加密:

​	同态加密（HE，homomorphic encryption）是一种允许在加密之后的密文上直接进行计算，且计算结果解密后和明文的计算结果一致的加密算法。

<img src="https://raw.githubusercontent.com/LifeSum12/typora-image/main/img/202209201439765.png" alt="image-20220920143925687" style="zoom: 33%;" /> 		

​	满足该式子代表是符合同态加密。⭐号表示其中一种运算（目前主要支持加法/乘法）



#### 分类：

（按照算法支持的运算类型和数量）

##### 1.部分同态加密（PHE，Partial HE）

​	指同态加密只对加法或乘法（其中一种）有同态性质。

<img src="https://raw.githubusercontent.com/LifeSum12/typora-image/main/img/202209201445803.png" alt="image-20220920144557760" style="zoom: 80%;" />

​	优点：原理简单，易实现。

​	缺点：仅支持一种运算

**经典算法：**

RSA算法和ElGamal算法为代表的**乘法同态加密**。

Paillier算法为代表的**加法同态加密**。

Boneh-Goh-Nissim方案为代表的**有限次数全同态加密**。

<img src="https://raw.githubusercontent.com/LifeSum12/typora-image/main/img/202209201648146.jpeg" alt="preload"  />

###### Paillier算法详解：

四个步骤：

​	密钥生成(公钥+私钥)

​	加密（用公钥），需要Encrtpt()加密函数

​	解密（用密钥），需要Decrypt ()解密函数

**1.密钥生成**

- gcd表示最大公因(约)数，lcm表示最小共倍数
- 长度相等：表示绝对值相同。
- Z*代表整数，且为正的。

<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e069e6d3c9ff42508fcac30536039cc8~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp" alt="img" style="zoom: 80%;" />

**2.加密**

<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/93c387f834ed44a19330e2789dbd0abc~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp" alt="img" style="zoom:80%;" />

**3.解密**

<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0cc37c0c87b4445189675c3c509d8a67~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp" alt="img" style="zoom:80%;" />

**同态加**

<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/103a88e3508b480eab2ecfe65011f428~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp" alt="img" style="zoom:80%;" />

**同态标量乘**

<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/125275f78db14db4a0dc824329861a84~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp" alt="img" style="zoom:80%;" />

原理详解：https://wdxtub.com/flt/flt-03/2020/12/02/

###### Paillier算法实现(Pyhton)：

```python
if __name__ == "__main__":
    #直接使用paillier函数生成密钥
    public_key, private_key = paillier.generate_paillier_keypair(n_length=10)
    print('pub', public_key.g, public_key.n)
    print('priv', private_key.p, private_key.q)
    A=[3,32]
    print('A', A)
    #公钥加密
    enA=[public_key.encrypt(x) for x in A]
    print(enA[0].ciphertext(False))
    print(enA[0].ciphertext(False).bit_length())
    B=[4,16]
    print('B', B)
    #公钥加密
    enB=[public_key.encrypt(x) for x in B]
    print(enB[0].ciphertext(False))
    print(enB[0].ciphertext(False).bit_length())
    #执行同态运算
    en=np.add(enA,enB)
    print(en[0].ciphertext(False))
    print(en[0].ciphertext(False).bit_length())
    #解密输出
    for x in en:
        print(private_key.decrypt(x))
```

###### Paillier算法在联邦学习应用：

下面模型采用：差分隐私加噪 + 同态加密

![image-20220925181846240](C:/Users/10275/AppData/Roaming/Typora/typora-user-images/image-20220925181846240.png)

本地梯度上传给服务器之前公钥加密，服务器聚合后的梯度发回给客户端，客户端私钥解密全局梯度。（全体客户端要使用同一套密钥）

- 恶意客户端不断参与训练，通过他人梯度g携带的信息，从而获取其他客户端信息。
- 公钥私钥由第三方来发，既不是服务器也不是客户端。（服务器也不知道加密后的数据，也防止了梯度传输过程中的泄露）



##### 2.全同态加密（FHE，Fully HE）

支持在密文上进行无限次数，任意类型的计算。

缺点：效率很低，目前还无法支撑大规模的计算。

**经典算法：**

Gentry方案为代表的第一代方案、以BGV方案和BFV方案为代表的第二代方案、GSW方案为代表的第三代方案。

支持浮点数近似计算的CKKS方案。

![preload](https://raw.githubusercontent.com/LifeSum12/typora-image/main/img/202209201648473.jpeg)

全同态加密发展到今天，已经出现了两个分支，一个分支是以计算算数电路为主(BGV, BFV,  CKKS)，另一个则以计算布尔电路为主(FHEW, TFHE)。





未完成工作：

​	0.完成paiilier、rsa的python api实现。查看python内部具体实现，或使用java手动具体实现。

https://wdxtub.com/flt/flt-03/2020/12/02/ 文章末尾链接有具体实现C++

​	wppcc比赛：顺便完成第一点代码实现+第二点Fate框架。

​	1.完成paiilier的联邦学习代码 ✔

​	2.使用fate等框架（之前没看完看视频，或自己找文章），fate里面也包含了paiilier算法等直接使用api

​	3.学习同态加密算法路线（知乎收藏夹）

​	4.差分隐私的学习和实现 ✔

​	5.fedmono，重新写代码

​		创造新的算法模型，若有需要乘法，采用全同态加密。

​	7.新想法看看✔

​	8.看看**增加数据异构**程序或者本地epoch=50能否提升。换个数据集。加大模型复杂程度。

​		现在是固定+/- 0.01，尝试着动态变化，loss差值更大权重改变大点（0.01~0.03）

​       看看能否解决掉队者问题。

​		看相关论文（在fomo论文找到英文关键词去搜，即改变权重）✔

- 权重进一步深化。（原理？参数变化？动态调整？T=200后取消？）
- 根据loss差值大小，来递增-μ的值。loss差值越大，减少/增大 权重的超参数μ也要越大。草稿纸 ⏳
- 比较fedprox scaffold算法。
- 换个数据集。cifar自己切分non-iid。eminst了解，scanffold论用这个。

​	9.gentry基础知识



6.老师之前7月发的好多篇论文



```text
No.1
```

```text
评判标准：最终全局模型 W 在全部用户的Loss损失总和。（越小表明该全局模型越好，利用大量用户帮忙训练一个模型来服务于大众）
个性化的评判标准：
		猜测，最终每个用户的模型 Wi 在本地的Loss损失总和。（越小表明该个性化模型越好，利用大量用户帮忙训练自己的）
```

联邦学习个性化：

上传模型：

​					不变。

服务器聚合并发放：

​					服务器计算所有参与用户相互的模型相似度(如：余弦相似度)，依次每个用户选择最接近自身的M个模型，聚合该M个模型(平均聚合or动态分权聚合)，并发放给该用户。							

下载模型：

​					每一次服务器给用户的全局模型为W<sub>R</sub>，在用户本地进行评估 （R为第n轮的全局模型，i 为用户索引数）

​					L<sup>i</sup><sub>R</sub>为本地损失，进行标准转换成0~1的权重，损失越大权重越小。L<sup>i</sup><sub>R</sub> => H<sup>i</sup><sub>R</sub>

​					在第 R round后，用户A的个性化模型为： 

​														     W<sub>A</sub> = H<sup>A</sup><sub>1</sub> * W<sub>1</sub>+  H<sup>A</sup><sub>2</sub> * W<sub>2</sub> + ...... +  H<sup>A</sup><sub>R</sub> * W<sub>R</sub>



```text
No.2
```

```text
评判标准：每轮(or上一轮)全局模型 和 局部模型Weight参数差异。具体到模型的每一层差异。
	例如：cnn模型有conv1.weight，conv1.bias, conv2.weight, conv2.bias共2层结构。 客户端A训练完上传的模型与全局模型差异表现在(conv1差异大，conv2差异小) ，而客户端B与全局模型差异表现在(conv1没差异，conv2差异大)，则聚合时分层聚合：
		聚合conv1层时：A的比例降低，B不变。
		聚合conv2、fc层时：B的比例降低，A不变。
```

```text
No.3
```

```text
Server开辟一个云空间，存储独立同分布的小量数据集。接收到传来的各个模型参数后，在云数据集进行评估loss后，重新对聚合权重赋值。在云空间表现好的本地模型参数 增大 聚合权重。
```

```text
No.4
```

```text
余弦距离-->解决non-iid使客户端漂移问题。
欧氏距离-->解决不同客户端算力差异问题。（一轮中更新epoch多与少）
	*当存在用户本地epoch过大，大于当前衡量标准。导致梯度bian'h，降低聚合权重。
	*当本地epoch过小，小于当前衡量标准。可能未达到训练要求，导致测试精度不够，降低聚合权重or不改变
	*衡量epoch标准：当前参与用户平均的欧氏距离
	
	--设定，fedavg需要在指定时间内完成E次epoch，未完成的丢弃掉。
	-不丢弃，直接聚合。（fedprox）
	-不丢弃，但降低E次数少的
```

```text
No.5
```

```text
Server开辟一个云空间，存储独立同分布的小量数据集。以该小型数据集来调整列表信息聚合方向。
	开始前，先度量云空间上的的数据分布信息，并发放给全体用户。
	1用户选择：根据本地数据度量的分布信息 与 云端的进行比较，进行排序，尽量选择相似云端数据的用户。
		根据用户参与次数 和 相似度来权衡 选择的排序。
		相似度高的客户端，允许本地epoch多次。
	2聚合时：对于这一轮发放的模型，Server端会先在云端进行训练得到Ws模型。通过对比该模型的余弦距离来分配权重。


1思路，
	在南京邮电大学论文中是使用云端iid数据集，与各客户相似度比较。越差的（越non-iid）每次聚合权重分配越少。（权重基本固定）
	思路1中，未来防止相似度高的用户多次被选择，加入参与次数的权衡。
	思路1中，度量相似度方法可用曼哈顿距离（解决标签skew问题）
	
2思路：
在fast-converge论文中，
	特点：①客户端上传模型是和聚合的平均模型比较余弦距离。
		 ②余弦权重是累加平均的，防止瞬时。
	缺点：①若参与用户是大量的，挑选训练的用户全都是non-iid则，多轮local epoch，该轮平均模型的走向就是很偏的，动态权重聚合使得模型更差。
		②（已验证）在10个用户,E=1情况下，异构用户占比大时候，需要20轮(该时期不如fedavg)调整期来调整聚合权重，才能后期超越fedavg。但整理来讲在10个用户，无论异构用户只有1个或9个时候，FedADP都优于fedavg。异构用户越多则提升越大。
		 在100个用户，E=1情况下，non-iid=1（两类标签数据），每次选用C=0.1的用户，fedadp相对fedavg没什么优势，几乎一样。
		 在100个用户，E=5情况下，non-iid=1（两类标签数据），每次选用C=0.1的用户，fedadp相对fedavg没什么优势，几乎一样。
		 在100个用户，E=5情况下，non-iid=4，non-idd-frac=0.7/0.9，每次选用C=0.1的用户，fedadp相对fedavg没什么优势，几乎一样。(在non-iid-frac=0.9，fedadp反而lue不如fedavg)，在10个异构用户聚合时，fedadp会加剧朝该类型异构用户多的方向移动。
			原因：100轮也意味着每个用户平均参与10次，但异构用户参与越多才能计算出余弦角度越大，所有参与的少的异构用户不会被算法认为是无贡献的用户。增大E=5好像也没变化
在High precision深圳大学论文中，
	特点：①客户端上传模型是和“上轮服务器发放模型”比较余弦距离。
		 ②不是通过余弦值来分配权重，而是对参与客户端余弦值进行k-means聚类分为好/坏两类，再进行权重分配，过滤到异常节点。
在FNCS哈工大论文中，
	特点：①客户端上传模型是和聚合的平均模型比较余弦距离。
		 ②获取余弦的向量与(1,1,...1)再计算余弦才得到余弦值float型。选择前m个余弦相似度高的用户参与训练。
		 ③分析到模型深层梯度散度比较大，对目标函数增加了惩罚性 h(w)= F(w)+O，需要最后一层散度小，即余弦相似度高。
	但思路2中，采取比较的是完全iid云端模型，方向更加正确。
3思路：
	如余弦值很相似了，并且欧几里得距离变化很小了，证明这个节点已经完成了使命。可以不选了
```



![image-20221212205728913](C:/Users/10275/AppData/Roaming/Typora/typora-user-images/image-20221212205728913.png)

```text
no.6
```

基于余弦距离的分层的动态聚合

​	将模型分为base层和high层，如cnn模型中conv1，conv2，fc1为base层，fc2为high层。

​	对于base层聚合，则使用全局模型梯度作为标准，动态聚合。

​	对于high层（non-iid在深层网络中的散度很大），则使用server端数据作为标准，动态聚合。

在Fedadp中，浅层相较权重散度小，使得长轮次才可识别出贡献更大的节点。

​	如cnn中，conv1需要70~80轮才能正确识别。conv2需要10~20轮才能正确识别。

​					 fc1在3~5轮就能正确识别。fc2在3~5轮就能正确识别。



### **差分隐私**:

​	主要是通过使用随机噪声来确保，查询请求公开可见信息的结果，并不会泄露个体的隐私信息，即提供一种当从统计数据库查询时，最大化数据查询的准确性，同时最大限度减少识别其记录的机会，简单来说，就是**保留统计学特征的前提下去除个体特征以保护用户隐私。**

<img src="https://raw.githubusercontent.com/LifeSum12/typora-image/main/img/202210281637049.webp" alt="img" style="zoom: 67%;" />

#### 定义公式

目的是使的这两个相邻分布尽可能地接近，那么衡量两个分布 Y,Z 的差异自然可以用到我们熟悉的`KL-Divergence`：

<img src="https://raw.githubusercontent.com/LifeSum12/typora-image/main/img/202210281706676.jpeg" alt="img" style="zoom:80%;" />

但是我们并不关心这两个分布的整体差异，我们只需要两个分布在差距最大的情况下能够被bound住，所以引入了`MAX-Divergence`，并且使得它小于 ε ：

<img src="https://raw.githubusercontent.com/LifeSum12/typora-image/main/img/202210281707787.png" alt="img" style="zoom:67%;" />



化简一下，利用 e [指数运算](https://www.zhihu.com/search?q=指数运算&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A"139114240"})将 ln 符号消去，然后将左边分母移到右边，就可以得到 **差分隐私定义** 了。

<img src="https://raw.githubusercontent.com/LifeSum12/typora-image/main/img/202210281708459.png" alt="img" style="zoom:80%;" />



如在下图两种相邻分布中，ε 就被称为隐私预算，一般而言， ε 越小，隐私保护越好，但是需要加入的噪声就越大，数据可用性就下降了。

![img](https://raw.githubusercontent.com/LifeSum12/typora-image/main/img/202210281709145.jpeg)

联邦学习添加噪声算法：目前主要就是拉普拉斯噪声 和 高斯噪声。



#### 三种机制

对于`数值型`的数据，一般采用**拉普拉斯 (Laplace)** 或者 **高斯机制**，对得到数值结果加入随机噪声即可实现差分隐私；

而对于`非数值型`的数据，一般采用 **指数机制** 并引入一个`打分函数`，对每一种可能的输出都得到一个分数，归一化之后作为查询返回的概率值。





## 联邦学习隐私保护

前提：梯度可以逆推出原始数据（通过随机生成数据一同参与训练，训练多次后结果）



一般使用同态加密算法PHE，多见为加法。（因为联邦学习中，需对中间梯度结果进行聚合）

论文：Secure federated matrix factorization









## Q1杨强综述

2. 联邦学习
   - 2.1 联邦学习的定义
   - 2.2 联邦学习的隐私
   - 2.3 联邦学习的分类
     - 2.3.1 横向联邦学习
     - 2.3.2 纵向联邦学习
     - 2.3.3 联邦迁移学习
   - 2.4 联邦学习系统的架构
     - 2.4.1 **横向联邦学习**的架构
     - 2.4.2 **纵向联邦学习**的架构
     - 2.4.3 **联邦迁移学习**的架构
     - 2.4.4 激励机制







